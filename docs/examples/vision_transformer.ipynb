{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# the pre-installed version of Jax is very old\n",
        "# !pip install -U jax[tpu]==0.4.19 jaxlib==0.4.19 -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install haliax torchvision\n",
        "!pip install \"haliax @ git+https://github.com/stanford-crfm/haliax.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ-WJ78itKt0",
        "outputId": "bb21a3ba-83cd-495d-c840-b88e0c25fa17"
      },
      "id": "yJ-WJ78itKt0",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda11_pip] in /usr/local/lib/python3.10/dist-packages (0.4.20)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.11.3)\n",
            "Requirement already satisfied: jaxlib==0.4.20+cuda11.cudnn86 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (0.4.20+cuda11.cudnn86)\n",
            "Collecting nvidia-cublas-cu11>=11.11 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11>=8.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cudnn_cu11-8.9.6.50-py3-none-manylinux1_x86_64.whl (699.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.9/699.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11>=10.9 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11>=11.4 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11>=11.7 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11>=2.18.3 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11 (from nvidia-cudnn-cu11>=8.8->jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b7f7fe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.096659Z",
          "start_time": "2023-11-03T19:38:35.073511Z"
        },
        "id": "f4b7f7fe"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "from typing import Callable, Dict, Optional, Type\n",
        "\n",
        "import equinox as eqx\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrandom\n",
        "from jaxtyping import PRNGKeyArray, Array\n",
        "\n",
        "import haliax as hax\n",
        "import haliax.jax_utils\n",
        "import haliax.nn as hnn\n",
        "from haliax import Axis, NamedArray\n",
        "from haliax.jax_utils import named_call, shaped_rng_split\n",
        "from haliax.nn.scan import Stacked\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e55e43bb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.098922Z",
          "start_time": "2023-11-03T19:38:35.077939Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e55e43bb",
        "outputId": "7d8bc48b-6a52-4446-c888-d77e2bdc3108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu\n"
          ]
        }
      ],
      "source": [
        "# Check if JAX is using GPU.\n",
        "from jax.lib import xla_bridge\n",
        "print(xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67205cc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.113872Z",
          "start_time": "2023-11-03T19:38:35.083133Z"
        },
        "id": "f67205cc"
      },
      "outputs": [],
      "source": [
        "# Axes\n",
        "\n",
        "Height        = hax.Axis(\"height\", 32)      # Height of the input image.\n",
        "Width         = hax.Axis(\"width\", 32)       # Width of the input image.\n",
        "Channels      = hax.Axis(\"channels\", 3)     # Channels of the input image.\n",
        "Embed         = hax.Axis(\"embed_dim\", 512)  # Dimension of patch embedding vector.\n",
        "Heads         = hax.Axis(\"heads\", 8)        # Number of heads in self-attention.\n",
        "Mlp           = hax.Axis(\"mlp\", 256)        # Hidden dim of MLP in transformer block.\n",
        "Layers        = hax.Axis(\"num_layers\", 6)   # Number of layers in transformer.\n",
        "Classes       = hax.Axis(\"num_classes\", 10) # Number of classes.\n",
        "\n",
        "patch_size    = 4\n",
        "PatchHeight = Height.resize(patch_size)\n",
        "PatchWidth  = Width.resize(patch_size)\n",
        "\n",
        "BatchSize     = hax.Axis(\"batch_size\", 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46182d71",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.114077Z",
          "start_time": "2023-11-03T19:38:35.088540Z"
        },
        "id": "46182d71"
      },
      "outputs": [],
      "source": [
        "class ViTPatchEmbeddings(eqx.Module):\n",
        "    proj: hnn.Linear\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Channels,\n",
        "             PatchHeight,\n",
        "             PatchWidth,\n",
        "             Embed,\n",
        "             key):\n",
        "\n",
        "        # Linear projection.\n",
        "        proj = hnn.Linear.init(In=(PatchHeight, PatchWidth, Channels),\n",
        "                               Out=(Embed),\n",
        "                               key=key,\n",
        "                               use_bias=False)\n",
        "\n",
        "        return ViTPatchEmbeddings(proj)\n",
        "\n",
        "    def embed(self, x):\n",
        "        # Rearrange input into patches.\n",
        "        x = hax.rearrange(x, \"{ (height: nh ph) (width: nw pw)  } -> ... (position: nh nw) (height: ph) (width: pw)\", ph=patch_size, pw=patch_size)\n",
        "\n",
        "        # Apply linear projection to each patch.\n",
        "        x = self.proj(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371f53aa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.114137Z",
          "start_time": "2023-11-03T19:38:35.096025Z"
        },
        "id": "371f53aa"
      },
      "outputs": [],
      "source": [
        "class Attention(eqx.Module):\n",
        "    Embed: hax.Axis\n",
        "    Heads: hax.Axis\n",
        "    HeadSize: hax.Axis\n",
        "\n",
        "    c_attn: hnn.Linear\n",
        "    c_proj: hnn.Linear\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Embed, Heads, key):\n",
        "\n",
        "        # Get the dimension of each head.\n",
        "        HeadSize = hax.Axis(\"head_size\", Embed.size // Heads.size)\n",
        "\n",
        "        # Axis for splitting into queries, keys, and values.\n",
        "        Qkv = hax.Axis(\"qkv\", size=3)\n",
        "\n",
        "        k_attn, k_proj = jrandom.split(key, 2)\n",
        "        c_attn = hnn.Linear.init(In=Embed, Out=(Qkv, Heads, HeadSize), key=k_attn)\n",
        "        c_proj = hnn.Linear.init(In=(Heads, HeadSize), Out=Embed, key=k_proj)\n",
        "\n",
        "        return Attention(Embed, Heads, HeadSize, c_attn, c_proj)\n",
        "\n",
        "    def __call__(self, x):\n",
        "\n",
        "        q, k, v = self.c_attn(x).unbind(\"qkv\")\n",
        "\n",
        "        # Rename Pos for the key and value tensors.\n",
        "        k = k.rename({\"position\": \"position_key\"})\n",
        "        v = v.rename({\"position\": \"position_key\"})\n",
        "\n",
        "        weights = hax.nn.attention.dot_product_attention_weights(self.HeadSize, \"position_key\", q, k)\n",
        "        attn_out = haliax.dot(\"position_key\", weights, v)\n",
        "        x = self.c_proj(attn_out)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925ca6d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.115232Z",
          "start_time": "2023-11-03T19:38:35.100946Z"
        },
        "id": "925ca6d5"
      },
      "outputs": [],
      "source": [
        "class MLP(eqx.Module):\n",
        "\n",
        "    c_proj_up: hax.nn.Linear\n",
        "    c_proj_down: hax.nn.Linear\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Embed, Mlp, key, use_bias=True):\n",
        "        k_proj_up, k_proj_down = jrandom.split(key, 2)\n",
        "        c_proj_up   = hnn.Linear.init(Out=Mlp, In=Embed, key=k_proj_up, use_bias=use_bias)\n",
        "        c_proj_down = hnn.Linear.init(Out=Embed, In=Mlp, key=k_proj_down, use_bias=use_bias)\n",
        "        return MLP(c_proj_up, c_proj_down)\n",
        "\n",
        "    @named_call\n",
        "    def __call__(self, x):\n",
        "        x = self.c_proj_up(x)\n",
        "        x = hnn.gelu(x)\n",
        "        return self.c_proj_down(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7693c01f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.115320Z",
          "start_time": "2023-11-03T19:38:35.105809Z"
        },
        "id": "7693c01f"
      },
      "outputs": [],
      "source": [
        "class Block(eqx.Module):\n",
        "    mlp: MLP\n",
        "    attn: Attention\n",
        "    ln1: hnn.LayerNorm\n",
        "    ln2: hnn.LayerNorm\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Embed, Heads, Mlp, key):\n",
        "        k_mlp, k_attn = jax.random.split(key, 2)\n",
        "        mlp  = MLP.init(Embed, Mlp, key=k_mlp)\n",
        "        attn = Attention.init(Embed, Heads, key=k_attn)\n",
        "        ln1  = hnn.LayerNorm.init(Embed)\n",
        "        ln2  = hnn.LayerNorm.init(Embed)\n",
        "        return Block(mlp, attn, ln1, ln2)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ebc8c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.115366Z",
          "start_time": "2023-11-03T19:38:35.109662Z"
        },
        "id": "d3ebc8c6"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(eqx.Module):\n",
        "\n",
        "    blocks: hnn.Stacked[Block]\n",
        "    ln_f: hnn.LayerNorm\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Embed, Heads, Mlp, Layers, key):\n",
        "        blocks = hnn.Stacked.init(\n",
        "            Layers,\n",
        "            Block,\n",
        "        )(Embed, Heads, Mlp, key=jax.random.split(key, Layers.size))\n",
        "        ln_f = hnn.LayerNorm.init(Embed)\n",
        "        return VisionTransformer(blocks, ln_f)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.blocks.fold(x)\n",
        "        x = self.ln_f(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class ViTClassificationHeadModel(eqx.Module):\n",
        "\n",
        "    vision_transformer: VisionTransformer\n",
        "    patch_embeddings: ViTPatchEmbeddings\n",
        "    position_embeddings: hnn.Embedding\n",
        "    cls_token: NamedArray\n",
        "\n",
        "    ln: hnn.LayerNorm\n",
        "    proj: hnn.Linear\n",
        "\n",
        "    @staticmethod\n",
        "    def init(Height, Width, Channels, PatchHeight, PatchWidth, Embed, Heads, Mlp, Layers, Classes, key):\n",
        "        k_tr, k_pte, k_ppe, k_cls, k_proj = jax.random.split(key, 5)\n",
        "\n",
        "        # Initialize Patch Token Embeddings.\n",
        "        patch_embeddings = ViTPatchEmbeddings.init(Channels, PatchHeight, PatchWidth, Embed, k_pte)\n",
        "\n",
        "        # ViT.\n",
        "        vision_transformer = VisionTransformer.init(Embed, Heads, Mlp, Layers, k_tr)\n",
        "\n",
        "        # Since we prepend a cls_token to the input, Pos needs to be one larger than the number of patches.\n",
        "        num_patches = (Height.size // PatchHeight.size) * (Width.size // PatchWidth.size)\n",
        "        Pos = hax.Axis(\"position\", num_patches + 1)\n",
        "\n",
        "        # Patch Position Embeddings.\n",
        "        position_embeddings = hnn.Embedding.init(Pos, Embed, key=k_ppe)\n",
        "\n",
        "        # cls_token.\n",
        "        cls_token = hax.random.normal(k_cls, (Embed, Pos.resize(1)))\n",
        "\n",
        "        # final linear projection.\n",
        "        ln   = hnn.LayerNorm.init(Embed)\n",
        "        proj = hnn.Linear.init(Out=Classes, In=Embed, key=k_proj, use_bias=True)\n",
        "\n",
        "        return ViTClassificationHeadModel(vision_transformer,\n",
        "                                          patch_embeddings,\n",
        "                                          position_embeddings,\n",
        "                                          cls_token,\n",
        "                                          ln,\n",
        "                                          proj)\n",
        "\n",
        "    def __call__(self, x):\n",
        "\n",
        "        # Embed x as a sequence of patches.\n",
        "        x = self.patch_embeddings.embed(x)\n",
        "\n",
        "        # Prepend cls_token.\n",
        "        x = hax.concatenate(\"position\", [self.cls_token.broadcast_axis(BatchSize), x])\n",
        "\n",
        "        # Add position embeddings.\n",
        "        x_Pos = x.resolve_axis(\"position\")\n",
        "        pos_embeds = self.position_embeddings.embed(hax.arange(x_Pos))\n",
        "        x = x + pos_embeds\n",
        "\n",
        "        # Forward pass.\n",
        "        x = self.vision_transformer(x)\n",
        "\n",
        "        # Select output corresponding to cls_token.\n",
        "        x = x[{\"position\": 0}]\n",
        "        # x = x.mean(\"position\")\n",
        "\n",
        "        # Project output to number of classes.\n",
        "        x = self.ln(x)\n",
        "        x = self.proj(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:35.124946Z",
          "start_time": "2023-11-03T19:38:35.116642Z"
        },
        "id": "5dcdbcf3"
      },
      "id": "5dcdbcf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "847a3c19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-03T19:38:36.431593Z",
          "start_time": "2023-11-03T19:38:35.121172Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "847a3c19",
        "outputId": "8abd968e-c2d0-4ea2-fb58-ca4ddee859f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9044446.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting CIFAR/cifar-10-python.tar.gz to CIFAR\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Data Loaders.\n",
        "From https://docs.kidger.site/equinox/examples/vision_transformer/.\n",
        "\"\"\"\n",
        "batch_size=64\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    \"CIFAR\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train,\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    \"CIFAR\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test,\n",
        ")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
        ")\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_value_and_grad\n",
        "def compute_grads(\n",
        "    model: ViTClassificationHeadModel,\n",
        "    images: hax.NamedArray,\n",
        "    labels: hax.NamedArray,\n",
        "    key):\n",
        "    logits = model(images)\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits.array, labels.array)\n",
        "    return jnp.mean(loss)\n",
        "\n",
        "@eqx.filter_jit\n",
        "def step_model(\n",
        "    model: ViTClassificationHeadModel,\n",
        "    optimizer: optax.GradientTransformation,\n",
        "    state: optax.OptState,\n",
        "    images: hax.NamedArray,\n",
        "    labels: hax.NamedArray,\n",
        "    key,\n",
        "):\n",
        "    loss, grads = compute_grads(model, images, labels, key)\n",
        "    updates, new_state = optimizer.update(grads, state, model)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    return model, new_state, loss\n",
        "\n",
        "def train(\n",
        "    model: ViTClassificationHeadModel,\n",
        "    optimizer: optax.GradientTransformation,\n",
        "    state: optax.OptState,\n",
        "    data_loader: torch.utils.data.DataLoader,\n",
        "    num_steps: int,\n",
        "    print_every: int = 1000,\n",
        "    key=None,\n",
        "):\n",
        "    losses = []\n",
        "\n",
        "    def infinite_trainloader():\n",
        "        while True:\n",
        "            yield from data_loader\n",
        "\n",
        "    for step, batch in zip(range(num_steps), infinite_trainloader()):\n",
        "        images, labels = batch\n",
        "\n",
        "        images = hax.named(images.numpy(), (BatchSize, Channels, Height, Width))\n",
        "        labels = hax.named(labels.numpy(), BatchSize)\n",
        "\n",
        "        key, *subkeys = jax.random.split(key, num=batch_size + 1)\n",
        "        subkeys = jnp.array(subkeys)\n",
        "\n",
        "        (model, state, loss) = step_model(\n",
        "            model, optimizer, state, images, labels, subkeys\n",
        "        )\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "        if (step % print_every) == 0 or step == num_steps - 1:\n",
        "            print(f\"Step: {step}/{num_steps}, Loss: {loss}.\")\n",
        "\n",
        "    return model, state, losses"
      ],
      "metadata": {
        "id": "oxVyhLvzwtsg"
      },
      "id": "oxVyhLvzwtsg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ea7f28",
      "metadata": {
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2023-11-03T19:38:36.424411Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ea7f28",
        "outputId": "018f8d2e-e4d3-451f-de3c-b586e3facbcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0/1000000, Loss: 2.3670318126678467.\n",
            "Step: 1000/1000000, Loss: 1.3204742670059204.\n",
            "Step: 2000/1000000, Loss: 1.392897367477417.\n",
            "Step: 3000/1000000, Loss: 1.337120771408081.\n",
            "Step: 4000/1000000, Loss: 1.1908444166183472.\n",
            "Step: 5000/1000000, Loss: 0.9924536347389221.\n",
            "Step: 6000/1000000, Loss: 0.9787511825561523.\n",
            "Step: 7000/1000000, Loss: 1.06725013256073.\n",
            "Step: 8000/1000000, Loss: 1.0366957187652588.\n",
            "Step: 9000/1000000, Loss: 1.1439564228057861.\n",
            "Step: 10000/1000000, Loss: 1.0700474977493286.\n",
            "Step: 11000/1000000, Loss: 0.9560476541519165.\n",
            "Step: 12000/1000000, Loss: 0.8232935667037964.\n",
            "Step: 13000/1000000, Loss: 0.7857428789138794.\n",
            "Step: 14000/1000000, Loss: 0.733768105506897.\n",
            "Step: 15000/1000000, Loss: 0.5060813426971436.\n",
            "Step: 16000/1000000, Loss: 0.6339681148529053.\n",
            "Step: 17000/1000000, Loss: 0.790744423866272.\n",
            "Step: 18000/1000000, Loss: 0.545936107635498.\n",
            "Step: 19000/1000000, Loss: 0.732439398765564.\n",
            "Step: 20000/1000000, Loss: 0.5827034711837769.\n",
            "Step: 21000/1000000, Loss: 0.7747631072998047.\n",
            "Step: 22000/1000000, Loss: 0.4894851744174957.\n",
            "Step: 23000/1000000, Loss: 0.37882155179977417.\n",
            "Step: 24000/1000000, Loss: 0.494605153799057.\n",
            "Step: 25000/1000000, Loss: 0.48977285623550415.\n",
            "Step: 26000/1000000, Loss: 0.532362699508667.\n",
            "Step: 27000/1000000, Loss: 0.2885732650756836.\n",
            "Step: 28000/1000000, Loss: 0.4511062502861023.\n",
            "Step: 29000/1000000, Loss: 0.44410353899002075.\n",
            "Step: 30000/1000000, Loss: 0.4453643560409546.\n",
            "Step: 31000/1000000, Loss: 0.5068289637565613.\n",
            "Step: 32000/1000000, Loss: 0.26449453830718994.\n",
            "Step: 33000/1000000, Loss: 0.4020524322986603.\n",
            "Step: 34000/1000000, Loss: 0.22299186885356903.\n",
            "Step: 35000/1000000, Loss: 0.31921666860580444.\n",
            "Step: 36000/1000000, Loss: 0.3629969358444214.\n",
            "Step: 37000/1000000, Loss: 0.3204885423183441.\n",
            "Step: 38000/1000000, Loss: 0.3623095154762268.\n",
            "Step: 39000/1000000, Loss: 0.3207293152809143.\n",
            "Step: 40000/1000000, Loss: 0.47906947135925293.\n",
            "Step: 41000/1000000, Loss: 0.4251318573951721.\n",
            "Step: 42000/1000000, Loss: 0.3456280827522278.\n",
            "Step: 43000/1000000, Loss: 0.19476789236068726.\n",
            "Step: 44000/1000000, Loss: 0.30285948514938354.\n",
            "Step: 45000/1000000, Loss: 0.17349191009998322.\n",
            "Step: 46000/1000000, Loss: 0.13309042155742645.\n",
            "Step: 47000/1000000, Loss: 0.24984347820281982.\n",
            "Step: 48000/1000000, Loss: 0.2196577489376068.\n",
            "Step: 49000/1000000, Loss: 0.1776508092880249.\n",
            "Step: 50000/1000000, Loss: 0.18862159550189972.\n",
            "Step: 51000/1000000, Loss: 0.30872249603271484.\n",
            "Step: 52000/1000000, Loss: 0.07885434478521347.\n",
            "Step: 53000/1000000, Loss: 0.14355763792991638.\n",
            "Step: 54000/1000000, Loss: 0.24854253232479095.\n",
            "Step: 55000/1000000, Loss: 0.22651495039463043.\n",
            "Step: 56000/1000000, Loss: 0.14442989230155945.\n",
            "Step: 57000/1000000, Loss: 0.1412152349948883.\n",
            "Step: 58000/1000000, Loss: 0.18996641039848328.\n",
            "Step: 59000/1000000, Loss: 0.06024029850959778.\n",
            "Step: 60000/1000000, Loss: 0.14063215255737305.\n",
            "Step: 61000/1000000, Loss: 0.08981111645698547.\n",
            "Step: 62000/1000000, Loss: 0.06501702964305878.\n",
            "Step: 63000/1000000, Loss: 0.1251937747001648.\n",
            "Step: 64000/1000000, Loss: 0.136862114071846.\n",
            "Step: 65000/1000000, Loss: 0.1011941060423851.\n",
            "Step: 66000/1000000, Loss: 0.140527606010437.\n",
            "Step: 67000/1000000, Loss: 0.05612226575613022.\n",
            "Step: 68000/1000000, Loss: 0.08264955133199692.\n",
            "Step: 69000/1000000, Loss: 0.10972285270690918.\n",
            "Step: 70000/1000000, Loss: 0.033975858241319656.\n"
          ]
        }
      ],
      "source": [
        "key = jax.random.PRNGKey(2023)\n",
        "\n",
        "key_mdl, key_train = jax.random.split(key, 2)\n",
        "\n",
        "model = ViTClassificationHeadModel.init(Height,\n",
        "                                        Width,\n",
        "                                        Channels,\n",
        "                                        PatchHeight,\n",
        "                                        PatchWidth,\n",
        "                                        Embed,\n",
        "                                        Heads,\n",
        "                                        Mlp,\n",
        "                                        Layers,\n",
        "                                        Classes,\n",
        "                                        key_mdl)\n",
        "\n",
        "optimizer = optax.adamw(\n",
        "    learning_rate=1e-4,\n",
        "    b1=0.9,\n",
        "    b2=0.999,\n",
        ")\n",
        "\n",
        "state = optimizer.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "model, state, losses = train(model, optimizer, state, trainloader, 1000000, print_every=1000, key=key_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7934200",
      "metadata": {
        "is_executing": true,
        "id": "f7934200"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "\n",
        "for batch in range(len(test_dataset) // batch_size):\n",
        "    images, labels = next(iter(testloader))\n",
        "\n",
        "    logits = jax.vmap(functools.partial(model, enable_dropout=False))(\n",
        "        images.numpy(), key=jax.random.split(key, num=batch_size)\n",
        "    )\n",
        "\n",
        "    predictions = jnp.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = jnp.mean(predictions == labels.numpy())\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "print(f\"Accuracy: {np.sum(accuracies) / len(accuracies) * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "is_executing": true,
        "id": "f8ddb8072c721813"
      },
      "id": "f8ddb8072c721813"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}